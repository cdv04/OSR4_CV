---
title: "OSR4_RegressionTree_Test"
author: "Claire Della Vedova"
date: "24 octobre 2017"
output: html_document
---




```{r  global_options}
knitr::opts_chunk$set(echo = FALSE, message = FALSE,
  warning = FALSE, fig.width = 15, fig.height = 12)

```


```{r package}
library('ggplot2')
library('dplyr')
library('tidyverse')
library('caret')
library('dummies')
library('FNN')
library('scales')
library('rpart')
library('rpart.plot')
library('randomForest')
library('knitr')
library('AppliedPredictiveModeling')
library('Rmisc')
library('gbm')

```



##1. Data

```{r data, results='hide'}

load("OSR4.RData")

# on travaille avec le jeu de données CsData2 qui ne contient plus l'unique donnée oceanique5 (variable OrigineCrue3)
 
summary(Csdata2)
dim(Csdata2)
str(Csdata2)
tail(Csdata2,15)

```

Les 10 dernières lignes ne comportent pas de données de débit et de charge ==> on les supprime pour la prédiction.


```{r data2,results='hide'}

# on enlève les 10 premières lignes
Csdata3<- Csdata2 %>%
  filter(Debit_max!="NA")

tail(Csdata3,15)
summary(Csdata3)
```


##2. Visualizations 

###2.1 Cs137 en fonction des potentielles variables prédictives numériques

```{r visualizationN1}

ind_predictorsMoy <- c(13,19,25)

# Les predicteurs Moy 
transparentTheme(trans = .4)
featurePlot(x=mydata2[, c(ind_predictorsMoy,29)],
            y=mydata2$Cs137,
            col=as.numeric(mydata2$Prelevement),
            plot="scatter",
            shape=22)

```


###2.1 Cs137 en fonction des potentielles variables prédictives numériques mais avec transformation log

```{r visualizationN2}

# Les predicteurs Moy avec une transfo log
transparentTheme(trans = .4)
featurePlot(x=log10(mydata2[, c(ind_predictorsMoy,29)]),
            y=log10(mydata2$Cs137),
            col=as.numeric(mydata2$Prelevement),
            plot="scatter",
            shape=22)

```



###2.3 Cs137 en fonction de l'origine de la Crue (variable OrigineCrue3)

```{r plotOrigineCrue3}
Csdata_SE2 <- summarySE(Csdata2, measurevar = "Cs137", groupvars = "OrigineCrue3")

ggplot(Csdata_SE2, aes(x=OrigineCrue3,y=Cs137, colour=OrigineCrue3))+
  geom_point(size=5)+
  geom_errorbar(aes(ymax=Cs137-ci, ymin=Cs137+ci))+
  ylim(c(0,80))+
  geom_text(aes(label=N, y=1))+
  theme(axis.text.x= element_text( angle=45, size=12))+
  geom_jitter(data=Csdata2, aes(x=OrigineCrue3,y=Cs137))


```


###2.3 Cs137 en fonction du type de prélèvement

```{r plotPrelevement}


Csdata_SE2bis <- summarySE(Csdata2, measurevar = "Cs137", groupvars = "Prelevement")

ggplot(Csdata_SE2bis, aes(x=Prelevement,y=Cs137, colour=Prelevement))+
  geom_point(size=5)+
  geom_errorbar(aes(ymax=Cs137-ci, ymin=Cs137+ci))+
  ylim(c(0,80))+
  geom_text(aes(label=N, y=1))+
  theme(axis.text.x= element_text( angle=45, size=12))+
  geom_jitter(data=Csdata2, aes(x=Prelevement,y=Cs137))

```

##3. Arbres de régression

```{r dummyvar}

data_tmp <- Csdata3[, c(9,4,13,19,25,29,31)]
names(data_tmp)

dum <- dummyVars(~Prelevement + OrigineCrue3, data=data_tmp) # creation des dummy variables
data_tmp <- cbind(data_tmp, predict(dum, newdata=data_tmp)) 
names(data_tmp)
data_tmp2 <- data_tmp[,-c(2,7)] # on enleve les variable afcteurs qui ont été remplacé par des dummy
names(data_tmp2)


```



###3.1 sans log des données prédictives numériques et q'avec les variables prédictives charge, débit, et OrigineCrue3 (dummy)

```{r tree1,fig.height=5, fig.width=5}

mydata_tree1 <-  data_tmp2[,c(1,2,3,10:16)]

set.seed(1000)
t.idx <- createDataPartition(mydata_tree1$Cs137, p=0.7, list = FALSE)


tree1 <- rpart(Cs137~ .,data=mydata_tree1[t.idx,])
tree1
prp(tree1, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")
```

#### Prunning 

```{r prunning1,fig.height=5, fig.width=5}



tree1$cptable
#0.6101749 +0.1284660 = 0.7386409 ==> on prend CP= 0.10679333  (2ème ligne)


plotcp(tree1)

# prunning
# bfit1pruned <- prune(bfit1, cp= 0.10679333 )
# prp(bfit1pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
# varlen=8, shadow.col="gray")



tree1_pruned <- prune(tree1, cp= 0.01 )
prp(tree1_pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")



# RMSE sur testing


preds.tree1 <- predict(tree1_pruned, mydata_tree1[-t.idx,])
rmse_tree1 <- sqrt(mean((preds.tree1 - mydata_tree1[-t.idx,"Cs137"])^2))
rmse_tree1

plot(preds.tree1, Csdata3[-t.idx, 9])
abline(a=0,b=1,  col="red")
# =>RMSE = 7.90
```

La RMSE de l'arbre de régression est :`r rmse_tree1 `

```{r tree1_importante}
tree1_pruned$variable.importance
barplot(tree1_pruned$variable.importance)

```



###3.2 sans log des données prédictives numériques mais avec toutes les variables prédictives  :charge, débit, Flux_MES ,Periode de Retour, OrigineCrue3 (dummy) + prelevement (dummy)


```{r tree2,fig.height=5, fig.width=5}

mydata_tree2 <-  data_tmp2

set.seed(1000)
t.idx <- createDataPartition(mydata_tree2$Cs137, p=0.7, list = FALSE)



tree2 <- rpart(Cs137~ .,data=mydata_tree2[t.idx,])
tree2
prp(tree2, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")
```

#### Prunning 

```{r prunning2,fig.height=5, fig.width=5}



tree2$cptable


plotcp(tree2)


tree2_pruned <- prune(tree2, cp= 0.01189548  )
prp(tree2_pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")



# RMSE sur testing


preds.tree2 <- predict(tree2_pruned, mydata_tree2[-t.idx,])
rmse_tree2 <- sqrt(mean((preds.tree2 - mydata_tree2[-t.idx,"Cs137"])^2))
rmse_tree2
# 7.55
plot(preds.tree2, Csdata3[-t.idx, 9])
abline(a=0,b=1,  col="red")
# 
```

La RMSE de l'arbre de régression est :`r rmse_tree2 `

```{r tree2_importante}
tree2_pruned$variable.importance
barplot(tree2_pruned$variable.importance)

```



###3.3 sans log des données prédictives numériques mais avec les variables prédictives charge, débit, OrigineCrue3 (pas dummy)


```{r tree1_bis,fig.height=5, fig.width=5}




mydata_tree1_bis <-  data_tmp[,c(1,3,4,7)]

set.seed(1000)
t.idx <- createDataPartition(mydata_tree1_bis$Cs137, p=0.7, list = FALSE)



tree1_bis <- rpart(Cs137~ .,data=mydata_tree1_bis[t.idx,])
tree1_bis
prp(tree1_bis, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")
```

#### Prunning 

```{r prunning1bis,fig.height=5, fig.width=5}



tree1_bis$cptable


plotcp(tree1_bis)


tree1_bis_pruned <- prune(tree1_bis, cp= 0.01132182 )
prp(tree1_bis_pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")



# RMSE sur testing
preds.tree1_bis <- predict(tree1_bis_pruned, mydata_tree1_bis[-t.idx,])
rmse_tree1_bis <- sqrt(mean((preds.tree1_bis - mydata_tree1_bis[-t.idx,"Cs137"])^2))
rmse_tree1_bis
# 7.825769
plot(preds.tree1_bis, Csdata3[-t.idx, 9])
abline(a=0,b=1,  col="red")

```

La RMSE de l'arbre de régression est :`r rmse_tree1_bis `

```{r tree1bis_importante}
tree1_bis_pruned$variable.importance
barplot(tree1_bis_pruned$variable.importance)

```




###3.4 sans log des données prédictives numériques mais avec les 6 variables prédictives et les catégories non dummy


```{r tree2bis,fig.height=5, fig.width=5}

mydata_tree2bis <- data_tmp[, c(1:7)] 

set.seed(1000)
t.idx <- createDataPartition(mydata_tree2bis$Cs137, p=0.7, list = FALSE)



tree2bis <- rpart(Cs137~ .,data=mydata_tree2bis[t.idx,])
tree2bis
prp(tree2bis, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")
```

#### Prunning 

```{r prunning2,fig.height=5, fig.width=5}



tree2bis$cptable


plotcp(tree2bis)


tree2bis_pruned <- prune(tree2bis, cp=  0.01891721  )
prp(tree2bis_pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")



# RMSE sur testing


preds.tree2bis <- predict(tree2bis_pruned, mydata_tree2bis[-t.idx,])
rmse_tree2bis <- sqrt(mean((preds.tree2bis - mydata_tree2bis[-t.idx,"Cs137"])^2))
rmse_tree2bis
#7.769486

plot(preds.tree2bis, Csdata3[-t.idx, 9])
abline(a=0,b=1,  col="red")
# 
```

La RMSE de l'arbre de régression est :`r rmse_tree2bis `

```{r tree2bis_importante}
tree2bis_pruned$variable.importance
barplot(tree2bis_pruned$variable.importance)

```


**DANS TOUS LES CAS UTILISER TOUTES LES VARIABLES REDUIT LA RMSE, PARFOIS UTILISER LES DUMMY VARIABLES ET MIEUX QUE LES VARIABLES CATEGORIELLE INITIALES**


## 4. Arbres de régression avec les log

###4.1 avec 6 variables prédictives et les facteurs pas en dummy

```{r treeLog3VDum,fig.height=5, fig.width=5}

mydata_treeL6D <- mydata_tree2bis

mydata_treeL6D$Cs137_log <- log10(mydata_treeL6D$Cs137 )
mydata_treeL6D$Debit_moy_log <- log10(mydata_treeL6D$Debit_moy )
mydata_treeL6D$Charge_moy_log <- log10(mydata_treeL6D$Charge_moy )
mydata_treeL6D$FluxMES_moy_log <- log10(mydata_treeL6D$FluxMES_moy )
mydata_treeL6D$ReturnPeriod_log <- log10(mydata_treeL6D$ReturnPeriod)

mydata_treeL6D <- mydata_treeL6D[,-c(1,3:6)]


set.seed(1000)
t.idx <- createDataPartition(mydata_treeL6D$Cs137, p=0.7, list = FALSE)

#voir comment écritre aurtomatiquement les formlues


treeL6D <- rpart(Cs137_log~. , data = mydata_treeL6D[t.idx,])
treeL6D
prp(treeL6D, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")
```

#### Prunning 

```{r prunning2,fig.height=5, fig.width=5}



treeL6D$cptable


plotcp(treeL6D)


treeL6D_pruned <- prune(treeL6D, cp=  0.02288295   )
prp(treeL6D_pruned, type=2, nn=TRUE, fallen.leaves=TRUE, faclen=4, 
varlen=8, shadow.col="gray")



# RMSE sur testing


preds.treeL6D <- predict(treeL6D_pruned, mydata_treeL6D[-t.idx,])
rmse_treeL6D <- sqrt(mean((10^(preds.treeL6D) - mydata_tree2bis[-t.idx,"Cs137"])^2))
rmse_treeL6D

plot(10^(preds.treeL6D), Csdata3[-t.idx, 9])
abline(a=0,b=1,  col="red")
# 
```

La RMSE de l'arbre de régression est :`rmse_treeL6D `

```{r tree3_importante}
treeL6D_pruned$variable.importance
barplot(treeL6D_pruned$variable.importance)

```


on repart sur le tree2 qui a la plus faible rmse

```{r}



```



## On fait un arbre sans log, sans standardisation et sans dummy et avec les 6 variables et on test 10 jeux training aléatoires





